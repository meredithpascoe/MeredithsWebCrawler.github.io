# -*- coding: utf-8 -*-
"""weather.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sDadjgEuQ0OYXFlf7G2v3Mv3YpTx4zj3
"""

# Import Requests library 
import requests
# Download webpage using requests.get
page = requests.get("https://forecast.weather.gov/MapClick.php?lat=42.2408&lon=-83.6131#.YmF-q9PMKUk")
# Import BeautifulSoup library and create a class to parse the webpage
from bs4 import BeautifulSoup
soup = BeautifulSoup(page.content, 'html.parser')

# Capture all the extended forecast items 
seven_day = soup.find(id="seven-day-forecast")
forecast_items = seven_day.find_all(class_="tombstone-container")

# Find all the time period names used in the seven day forecast
period_tags = seven_day.select(".tombstone-container .period-name")
periods = [pt.get_text() for pt in period_tags]
periods

# Find the weather conditions summary, temperature, and and conditions description for the various time periods in the seven day forecast
short_descs = [sd.get_text() for sd in seven_day.select(".tombstone-container .short-desc")]
temps = [t.get_text() for t in seven_day.select(".tombstone-container .temp")]
descs = [d["title"] for d in seven_day.select(".tombstone-container img")]
print(short_descs)
print(temps)
print(descs)

# Import Pandas library
import pandas as pd
#Add data to a Pandas DataFrame
weather = pd.DataFrame({
    "period": periods,
    "short_desc": short_descs,
    "temp": temps,
    "desc":descs
})
weather

# Create data on to Google Drive
from google.colab import drive
# Mount your Drive to the Colab VM.
#drive._mount('/gdrive')
drive.mount('/gdrive')

# the file path where to store the output csv on google drive
output_file = '/gdrive/My Drive/weather.csv'

# Save the dataframe as a csv file
weather.to_csv(output_file, index=False)

from google.colab import files
files.download(output_file)
print("the csv has been downloaded to your local computer. The program has been completed successfully")